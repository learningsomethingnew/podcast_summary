{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/learningsomethingnew/podcast_summary/blob/main/summarize_podcasts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrHN5XDeRkXL"
      },
      "source": [
        "Click üëÜ this to begin if you found this on Github.\n",
        "\n",
        "# Podcast Summarizer\n",
        "Podcast are a wealth of information, but they tend to have tons of episodes that are upwards of 1-2 hours per. This Google Colab will take a given podcast and will create a csv document for each audio/mp3 audio episode for free! There is also an option to use OpenAI's GPT3, which does charge, but is super cheap. \n",
        "\n",
        "## Details\n",
        "Each episode will get a text file in the transcription folder that will contain:\n",
        "\n",
        "*   Speaker identification (optional)\n",
        "*   Using Speach to Text transcribe what was said by each speaker. Example: \n",
        "  > 0:00:00.000-0:00:33.960> SPEAKER_01:  Welcome to the Profitable Farmer podcast, where we share stories and tips to help you run a better farming business and create your very own freedom farm. If you're looking to work smarter and not harder in your farm business, welcome, you're in the right place. .... \n",
        "*   Summerize the episode\n",
        "  > FarmTender was founded in March 2012, but the backstory of its founder goes back further. He grew up on a family farm in the Wimmera and made the decision to move away from primary production so he could pursue something new. He had an interest in building databases and the internet, and was brave enough to leave something that offered certainty to go and try something else. After trying a few different things, he heard a farmer at a field day asking why he couldn't sell his products online. This gave him the idea for FarmTender, and he worked with a developer to get it up and running. It was a tough process, but he had a database of 2000 members to help him get started. With lots of cold calling and content creation, FarmTender has grown significantly since then....\n",
        "\n",
        "### Note About The Summaries\n",
        "This project is aiming for good enough to quickly read through.\n",
        "\n",
        "## FAQ\n",
        "\n",
        "### Does my computer need a graphics card?\n",
        "NO! This runs in the cloud and does NOT require your personal machine to have a graphics card.\n",
        "\n",
        "### Where is the output located?\n",
        "gDrive -> My Drive -> Summarize_Podcasts -> PODCAST_NAME_HERE -> Transcript <br>\n",
        "\n",
        "In you gDrive there will be a directory called \"Summarize_Podcasts\". When you run this notebook for a podcast a directory will be created in this folder by that name. Podcast \"Reply All\" will be \"replyall\". In there you will find the \"transcript\" folder where you will find the transcript and summary.\n",
        "\n",
        "### How long does this need to run?\n",
        "* In testing, for a 1 hour podcast episode it takes around 20-25 minutes.\n",
        "\n",
        "### Which Runtime Type?\n",
        "You will need to use a **GPU** Runtime. In order to select a runtime, on the menu: \n",
        "1. Click ‚ÄúRuntime‚Äù -> ‚ÄúChange runtime type‚Äù\n",
        "2. Under \"Hardware Accelerator\" -> select \"GPU\" \n",
        "3. Click ‚ÄúSave‚Äù\n",
        "\n",
        "### How do I run this?\n",
        "1. Go to the Required Information section, below, and fill out the forms.\n",
        "2. Once filled in, on the menu, click ‚ÄúRuntime‚Äù -> ‚ÄúRun All‚Äù\n",
        " * Or you can press \"shift + enter\" on your keyboard until you get to the end of this document to run each cell.\n",
        "\n",
        "### Keep this tab open and don't let your computer sleep\n",
        "Colab, unless on the $50 dollar plan, requires this tab to stay open and that the computer running this tab stays awake while executing\n",
        "\n",
        "### Uh oh, the runtime shutdown before completing\n",
        "No need to worry. This code has been setup to pick up where it left off in processing. Just reconnect, with GPU collab. Depending on how long each episode is and how many episodes, this could take a few sessions. \n",
        "\n",
        "### Empty gDrive Trash\n",
        "If you run this a few times, you will need to empty your gdrive trash to free up space. [More information can be found here on how to do that ](https://support.google.com/drive/answer/2375102?hl=en&co=GENIE.Platform%3DDesktop)\n",
        "\n",
        "### Which languages are supported?\n",
        "* English\n",
        "While Whisper does support additional languages, with varying degrees of accuracy, I don't know enough of the various languages to validate if the summarization is even in the \"good enough\" category. Reach out if you want to help.\n",
        "\n",
        "### How do I track progress?\n",
        "After you click the run button, scroll down to the bottom to see the logs to see the progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAZ-NuQBz33c",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown üëàüëàüëà Click this play button after filling out this form. Scroll down to see the progress\n",
        "import json\n",
        "from google.colab import drive\n",
        "import subprocess\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "# logging setup\n",
        "logger = logging.getLogger('podcast_summary')\n",
        "\n",
        "logging.basicConfig(\n",
        "  format='%(asctime)s - %(message)s', \n",
        "  level=logging.INFO,\n",
        "  force=True\n",
        ")\n",
        "\n",
        "#@title Please fill out this form\n",
        "\n",
        "#@markdown ## Podcast XML <img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/4/43/Feed-icon.svg/256px-Feed-icon.svg.png\" alt=\"RSS Feed Icon\" height=35; />\n",
        "#@markdown Please provide the Podcast's RSS Feed XML link here.\n",
        "\n",
        "podcast_xml = \"https://feeds.megaphone.fm/replyall\" #@param {type:\"string\"}\n",
        "#@markdown Number of episodes you would like to summarize, starting from most recent? Use 0 for all episodes.\n",
        "num_of_episodes = 5 #@param {type:\"integer\"}\n",
        "#@markdown <br>\n",
        "\n",
        "\n",
        "\n",
        "#@markdown ### Hugging Face Setup <img src=\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\" alt=\"RSS Feed Icon\" height=35; />\n",
        "#@markdown Do you want to get an output file that identifies each speaker? \n",
        "#@markdown If \"False\" then you can skip the api key\n",
        "identify_speakers = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "#@markdown 1. Please provide a Hugging Face READ api key. [You can get one by following this guide](https://huggingface.co/docs/hub/security-tokens)\n",
        "apikey_for_hugging_face = '' #@param {type:\"string\"}\n",
        "#@markdown 2. Visit [pyannote/speaker-diarization](https://huggingface.co/pyannote/speaker-diarization) and and accept user conditions <br> <img src=\"https://i.imgur.com/HpwAGpR.png\" alt=\"RSS Feed Icon\" height=120; />\n",
        "#@markdown 3. Visit [pyannote/segmentation](https://huggingface.co/pyannote/segmentation) and accept user conditions\n",
        "#@markdown <br>\n",
        "if identify_speakers and 'apikey_for_hugging_face' == \"\":\n",
        "  logger.error(\"No API Key\")\n",
        "  sys.exit(\"ERROR: !!!!! Please input an API key for Hugging Face\")\n",
        "\n",
        "#@markdown  ## Summarize Setup <img src=\"https://i.imgur.com/Mc95bds.png\" alt=\"RSS Feed Icon\" height=40; />\n",
        "\n",
        "#@markdown In order to summarize a podcast episode, you will need to select which tool you would like to use. This colab is setup with:<br>\n",
        "#@markdown * Sumy - A free library that uses Latent Semantic Analysis (LSA)... tldr: It is OK and summarizes by finding high value sentences \n",
        "#@markdown and combining them.\n",
        "#@markdown * GPT3 - Requires an [API key and a credit card after the free credits](https://elephas.app/blog/how-to-create-openai-api-keys-cl5c4f21d281431po7k8fgyol0). More advanced & powerful than Sumy.\n",
        "#@markdown   *  In testing, 3, 1 hour podcasts summarized cost me ~1 dollar USD. \n",
        "summarization_tool = \"Sumy (Free)\" #@param [\"Sumy (Free)\", \"GPT3 (Requires API Key)\"]\n",
        "#@markdown if you selected GPT3, you will need to input the API key here. Otherwise you can leave blank.\n",
        "apikey_for_openai = \"\" #@param {type:\"string\"}\n",
        "#@markdown <br>\n",
        "if summarization_tool.startswith(\"GPT3\") and apikey_for_openai == \"\":\n",
        "  logger.error(\"No API Key\")\n",
        "  sys.exit(\"ERROR: !!!!! Please input an API key for OpenAI\")\n",
        "\n",
        "#@markdown ## Optional Settings <img src=\"https://cdn2.iconfinder.com/data/icons/connectivity/32/setting-512.png\" height=30;>\n",
        "#@markdown Do you want to summarize each episode?\n",
        "summarize_episode = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "#@markdown Percent of sentences do you want to trim off the front and back of each\n",
        "#@markdown episode? The idea here is to skip ads, intros, and outros to reduce noise\n",
        "#@markdown for the summary. If 800 sentences, at 10%, 80 sentences from the front\n",
        "#@markdown  and back will be ignored for summarizing\n",
        "percent_sentences_to_skip = 4 #@param {type:\"slider\", min:0, max:40, step:1}\n",
        "\n",
        "#@markdown ### Google Drive <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Google_Drive_icon_%282020%29.svg/2295px-Google_Drive_icon_%282020%29.svg.png\" alt=\"RSS Feed Icon\" height=20; />\n",
        "#@markdown Free Colab has a limited runtime. By leveraging your Google Drive, we can iterate through the podcast \n",
        "#@markdown and pick back up where we left off after the runtime ends. \n",
        "logger.info('A pop up will appear asking for access to your gDrive.')\n",
        "drive.mount('/content/drive')\n",
        "#@markdown Google Drive Directory Path. (Can leave as default)\n",
        "path_to_use = \"/content/drive/MyDrive/Summarize_Podcasts\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Whisper (Speech To Text)\n",
        "#@markdown Which speech to text model would you like to use. The larger the model, \n",
        "#@markdown the more RAM is needed. Only change if you know about what this means\n",
        "whisper_model = \"medium.en\" #@param [\"large-v2\", \"large-v1\", \"large\", \"medium\", \"medium.en\", \"base\", \"base.en\", \"tiny\", \"tiny.en\", \"\"]\n",
        "#@markdown ### Storage Management\n",
        "#@markdown Do you want to delete the podcast MP3s after completion? Helps conserve gDrive space.\n",
        "#@markdown This is done after this code fully completes to reduce duplicate downloads\n",
        "delete_mp3s_when_done = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "#@markdown ### Auto Shutdown\n",
        "#@markdown If you want Colab to auto disconnect the environment when completed\n",
        "auto_shutoff = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "#@markdown üëáüëáüëá Progress logs will appear below this üëáüëáüëá \n",
        "\n",
        "\n",
        "# validate that we have the right runtime environment\n",
        "logger.info(\"Verifying the current runtime environment has a GPU\")\n",
        "result = subprocess.run([\"nvidia-smi\", \"-L\"], stdout=subprocess.PIPE)\n",
        "output = result.stdout.decode('utf-8')\n",
        "# catch the runtime if it does not have a GPU. Example output \"GPU 0: Tesla T4\"\n",
        "if 'gpu' not in output.lower():\n",
        "  logger.error(\"No GPU detected\")\n",
        "  logger.info(\"You will need to use a **GPU** Runtime. In order to select a runtime, on the menu:\") \n",
        "  logger.info(\"1. Click ‚ÄúRuntime‚Äù -> ‚ÄúChange runtime type‚Äù\")\n",
        "  logger.info(\"\"\"2. Under \"Hardware Accelerator\" -> select \"GPU\"\"\"\")\n",
        "  logger.info(\"\"\"3. Click ‚ÄúSave‚Äù\"\"\")\n",
        "  sys.exit(\"ERROR: !!!!! Please change the Runtime environment to include a GPU. See the instructions above.\")\n",
        "else: \n",
        "  logger.info(\"Runtime environment has a GPU! Now installing packages\")\n",
        "\n",
        "#################### PACKAGE INSTALLING\n",
        "################################################################################\n",
        "logger.info(\"Installing needed libraries\")\n",
        "\n",
        "def install_packages(packages: list):\n",
        "  \"\"\"\n",
        "  Checks to see if a specific package has already been installed\n",
        "  \"\"\"\n",
        "  logger.info(\"Checking if packages have already been installed\")\n",
        "  result = subprocess.run([\"pip\", \"freeze\"], stdout=subprocess.PIPE)\n",
        "  installed_packages = result.stdout.decode().split(\"\\n\")\n",
        "  packages_to_install = []\n",
        "  for package in packages:\n",
        "      package_installed = False\n",
        "      for p in installed_packages:\n",
        "          if package in p:\n",
        "              package_installed = True\n",
        "              break\n",
        "      if not package_installed:\n",
        "          packages_to_install.append(package)\n",
        "  if packages_to_install:\n",
        "    logger.info(f\"Installing {len(packages)} packages. This will take a few minutes\")\n",
        "    subprocess.run([\"pip\", \"install\", \"-q\"] + packages_to_install)\n",
        "    for package in packages_to_install:\n",
        "        logger.info(f\"Installed package {package}\")\n",
        "  else:\n",
        "    logger.info(\"All packages already installed\")\n",
        "\n",
        "packages = [\n",
        "  # requests for downloading the podcast feed and mp3s\n",
        "  \"requests\", \n",
        "  # for processing the podcast xml \n",
        "  \"feedparser\",\n",
        "  # for speech to text\n",
        "  \"git+https://github.com/openai/whisper.git\",\n",
        "]\n",
        "\n",
        "if identify_speakers:\n",
        "  logger.info(\"Identifying Speakers set to True.\")\n",
        "  packages += [\n",
        "          \"torch==1.11.0\",\n",
        "          \"torchvision==0.12.0\",\n",
        "          \"torchaudio==0.11.0\",\n",
        "          \"torchtext==0.12.0\",\n",
        "          \"speechbrain==0.5.12\",\n",
        "          \"pyannote.audio==2.1.1\",\n",
        "          \"pydub==0.25.1\"\n",
        "      ]\n",
        "\n",
        "# for text summarization\n",
        "if summarization_tool.startswith(\"GPT3\"):\n",
        "  logger.info(\"GPT3 selected for summarizing\")\n",
        "  packages += [\n",
        "      \"openai==0.26.4\",\n",
        "      \"backoff\"\n",
        "    ]\n",
        "else:\n",
        "  logger.info(\"Sumy selected for summarizing\")\n",
        "  packages+=[\"sumy==0.11.0\"]\n",
        "\n",
        "install_packages(packages)\n",
        "\n",
        "#################### PACKAGE IMPORTING\n",
        "################################################################################\n",
        "logger.info(\"Importing the packages\")\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "import gc\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "import google.colab\n",
        "from google.colab import runtime\n",
        "\n",
        "import feedparser\n",
        "import requests\n",
        "\n",
        "import backoff\n",
        "import whisper\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "if identify_speakers==True:\n",
        "  from pyannote.audio import Audio \n",
        "  from pyannote.audio import Pipeline\n",
        "  from pydub import AudioSegment\n",
        "  from pydub import silence\n",
        "  from pydub.silence import split_on_silence\n",
        "\n",
        "if summarization_tool.startswith(\"GPT3\"):\n",
        "  import openai\n",
        "  openai.api_key = apikey_for_openai\n",
        "else:\n",
        "  from sumy.parsers.plaintext import PlaintextParser\n",
        "  from sumy.nlp.tokenizers import Tokenizer\n",
        "  from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
        "  from sumy.nlp.stemmers import Stemmer\n",
        "  from sumy.utils import get_stop_words\n",
        "  \n",
        "\n",
        "# max length of the clips. We add .5 seconds to the front and back if we \n",
        "# split on silence as 30 seconds is the max length of whisper. Multiply by 1k\n",
        "# to get milliseconds\n",
        "audio_max_clip_length = 29 * 1000\n",
        "\n",
        "logger.info(\"Loading functions\")\n",
        "#################### FILE HANDLING\n",
        "################################################################################\n",
        "def file_path_validate_get(folder_path: str, file_name: str):\n",
        "  \"\"\"\n",
        "  validates that a path is available for a file. If it is not, then it will create\n",
        "  the path as needed.\n",
        "  save_path: the folder directory\n",
        "  file_name: the name of the file\n",
        "  return: str of file path\n",
        "  \"\"\"\n",
        "  if not os.path.exists(folder_path):\n",
        "      logger.info(f\"Creating directory '{folder_path}' in Google Drive\")\n",
        "      os.makedirs(folder_path)\n",
        "  return os.path.join(folder_path, file_name)\n",
        "\n",
        "def files_in_folder_delete(folder_path: str, file_type: str = None):\n",
        "  \"\"\"\n",
        "  Finds all of the files, or files by type, in the specified folder and\n",
        "  puts them into gDrive trash. Cannot hard delete.\n",
        "  folder_path: str path of folder\n",
        "  file_type: str file extension of files to delete (optional)\n",
        "  return: n/a \n",
        "  \"\"\"\n",
        "  for file_name in os.listdir(folder_path):\n",
        "    if file_type:\n",
        "      if not file_name.endswith(file_type):\n",
        "        continue\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)\n",
        "          \n",
        "def json_save_to(data: dict, file_path: str):\n",
        "  with open(file_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, ensure_ascii=False)\n",
        "\n",
        "def json_load(file_path: str):\n",
        "  \"\"\"\n",
        "  Check to see if the file is present. If it is, then return the file. If it \n",
        "  is not, return False.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "      return json.load(f)\n",
        "  except FileNotFoundError:\n",
        "    return False\n",
        "\n",
        "def file_write(directory: str, data: str):\n",
        "  with open(directory, 'w', encoding='utf-8') as f:\n",
        "    f.write(data)\n",
        "\n",
        "#################### ML MODEL LOADING\n",
        "################################################################################\n",
        "# create the path to save the model to\n",
        "path_ml_models = os.path.join(path_to_use, 'ml_models/')\n",
        "_ = file_path_validate_get(path_ml_models, \"\")\n",
        "\n",
        "# download the needed ML models\n",
        "# Diarization is the model needed to identify speakers\n",
        "# only load if we want to identify speakers\n",
        "if identify_speakers:\n",
        "  pipeline = Pipeline.from_pretrained('pyannote/speaker-diarization', \n",
        "                                      use_auth_token=apikey_for_hugging_face, \n",
        "                                      #this model doesn't look to see if it is cached\n",
        "                                      # cache_dir=path_ml_models \n",
        "                                      )\n",
        "\n",
        "    # setting up whisper for use with speaker identification\n",
        "  model = whisper.load_model(whisper_model, download_root=path_ml_models)\n",
        "\n",
        "#################### PODCAST DOWNLOADING\n",
        "################################################################################\n",
        "\n",
        "def mp3_download(url: str, file_name: str, save_path: str):\n",
        "  \"\"\"\n",
        "  From a given url, downloads the mp3 into a specified path\n",
        "  \"\"\"\n",
        "  file_path = file_path_validate_get(save_path, file_name)\n",
        "  response = requests.get(url)\n",
        "  open(file_path, 'wb').write(response.content)\n",
        "  logger.info(f\"Downloaded {file_name}\")\n",
        "  del response\n",
        "\n",
        "\n",
        "def podcast_feed_download(rss_feed_url: str):\n",
        "  \"\"\"\n",
        "  downloads the entire podcast's rss, performs a light refactoring\n",
        "  on the file, and then stores feed for later use/reference\n",
        "  \"\"\"\n",
        "  # get the rss_feed\n",
        "  feed = feedparser.parse(rss_feed_url)\n",
        "  logger.info(f\"There are {len(feed.entries)} episodes in this podcast\")\n",
        "  data = {\n",
        "      'title': feed.feed['title'].lower().replace(\" \", \"_\"),\n",
        "      'feed': feed.feed,\n",
        "      'entries': []\n",
        "  }\n",
        "  # keep the data that we want and add some flags for tracking progress\n",
        "  count = 0\n",
        "  for entry in feed.entries:\n",
        "    temp_entry = {}\n",
        "    temp_entry['title'] = entry['title']\n",
        "\n",
        "    # get the href link for the podcast audio file\n",
        "    for link in entry.links:\n",
        "      if link['type'] == 'audio/mpeg':\n",
        "        temp_entry['href'] = link['href']\n",
        "      else:\n",
        "        # ignore the items that don't have an audio href\n",
        "        continue\n",
        "    temp_entry['file_name'] = entry['title'].replace(\" \", \"_\").lower()+\".mp3\"\n",
        "    data['entries'].append(temp_entry)\n",
        "    \n",
        "  del temp_entry\n",
        "  del feed\n",
        "  return data\n",
        "  \n",
        "\n",
        "#################### AUDIO/MP3 MANAGEMENT\n",
        "################################################################################\n",
        "\n",
        "def match_target_amplitude(chunk, target_dBFS):\n",
        "  \"\"\"\n",
        "  Normalize given audio chunk\n",
        "  \"\"\"\n",
        "  return chunk.apply_gain(target_dBFS - chunk.dBFS)\n",
        "\n",
        "def chunk_normalize(chunk):\n",
        "  \"\"\"\n",
        "  Create a silence chunk that's 0.5 seconds (or 500 ms) long for padding\n",
        "  copied from https://stackoverflow.com/a/46001755\n",
        "  \"\"\"\n",
        "  silence_chunk = AudioSegment.silent(duration=500)\n",
        "  # add silence to the begging and end of the chunk\n",
        "  audio_chunk = silence_chunk + chunk + silence_chunk\n",
        "  # normalize the entire chunk\n",
        "  return match_target_amplitude(audio_chunk, -20.0)\n",
        "\n",
        "def chunk_save(chunk, chunk_index):\n",
        "  normalized_chunk = chunk_normalize(chunk)\n",
        "  normalized_chunk.export(path_split_mp3s + f\"chunk_{chunk_index}.mp3\", format=\"mp3\")\n",
        "\n",
        "def mp3_split(audio, start_time, end_time):\n",
        "  # Convert the start and end times from seconds to milliseconds\n",
        "  start_time_ms = start_time * 1000\n",
        "  end_time_ms = end_time * 1000\n",
        "  chunk = audio[start_time_ms:end_time_ms]\n",
        "  return chunk\n",
        "\n",
        "def mp3_convert_to_wav(mp3_file_path: str, wav_file_path: str):\n",
        "    # we need a wave file for us to determine speaker timing of each mp3 file\n",
        "    # check to see if the folders exists\n",
        "    sound = AudioSegment.from_mp3(mp3_file_path)\n",
        "    sound.export(wav_file_path, format=\"wav\")\n",
        "    logger.info(\"MP3 to WAV conversion successful\")\n",
        "    del sound\n",
        "\n",
        "def mp3_split_on_silence(chunk, silence_threshold=-50, min_silence_len=400, clip_duration=30*1000, chunk_index=\"\"):\n",
        "  # split up the audio into chunks\n",
        "  logger.debug(f\"Splitting up audio into chunks, chunk_index = {chunk_index}\")\n",
        "  chunks = split_on_silence(chunk, min_silence_len=min_silence_len, silence_thresh=silence_threshold)\n",
        "\n",
        "  for i, chunk in enumerate(chunks):\n",
        "    # identify if any chunks are longer than 29 secs, when saved we pad .5 second front and back\n",
        "    if len(chunk) > 29 * 1000:\n",
        "      mp3_split_on_silence(chunk, min_silence_len=min_silence_len-50, chunk_index=chunk_index+\".\"+str(i))\n",
        "    else:\n",
        "      temp = chunk_index+\".\"+str(i)\n",
        "      chunk_save(chunk, chunk_index+\".\"+str(i))\n",
        "  del chunk\n",
        "  del chunks\n",
        "\n",
        "def split_and_save_thread(audio, start_time, end_time, index):\n",
        "  duration = end_time - start_time\n",
        "  chunk = mp3_split(audio, start_time, end_time)\n",
        "  # if the segment is longer than audio_len_split\n",
        "  if duration > audio_max_clip_length/1000:\n",
        "    logger.debug(f\"This segment has duration of {duration} seconds\")\n",
        "    mp3_split_on_silence(chunk, silence_threshold=-50, min_silence_len=500, clip_duration=30*1000, chunk_index=str(index))\n",
        "  else:\n",
        "    chunk_save(chunk, index)\n",
        "  \n",
        "  del chunk\n",
        "\n",
        "def mp3_split_speaker_segments(audio_segments, mp3_file_path):\n",
        "  num_seg = len(audio_segments)\n",
        "  logger.info(f\"There are {num_seg} segments to split up. This will take a few minutes\")\n",
        "  # Load the entire mp3 file into memory\n",
        "  audio = AudioSegment.from_file(mp3_file_path, format=\"mp3\")\n",
        "\n",
        "  for index, segment in enumerate(audio_segments):\n",
        "    # split up the mp3 into various chunks to make transcribing easier\n",
        "    split_and_save_thread(audio, segment['start'], segment['stop'], index)\n",
        "\n",
        "  del audio\n",
        "\n",
        "\n",
        "#################### SPEAKER IDENTIFICATION/DIARIZATION\n",
        "################################################################################\n",
        "\n",
        "def capture_speaker_changes(diarization):\n",
        "  \"\"\"\n",
        "  Iterates through all of the turns from the diarization and adds up the\n",
        "  time that the same speaker speaks for to create one consistent clip vs smaller\n",
        "  clips.\n",
        "  returns: a list of dicts with keys \"speaker\", \"start\", \"stop\", \"duration\"\n",
        "  \"\"\"\n",
        "  result = []\n",
        "  current_speaker = None\n",
        "  for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "      start, stop = turn.start, turn.end\n",
        "      if current_speaker != speaker:\n",
        "        if current_speaker is not None:\n",
        "            result.append({\n",
        "                \"speaker\": current_speaker, \n",
        "                \"start\": start_time, \n",
        "                \"stop\": stop_time, \n",
        "                \"duration\": stop_time-start_time,\n",
        "                \"transcribed_text\": \"\"})\n",
        "        current_speaker = speaker\n",
        "        start_time = start\n",
        "        stop_time = stop\n",
        "      else:\n",
        "        stop_time = max(stop_time, stop)\n",
        "  if current_speaker is not None:\n",
        "    result.append({\n",
        "      \"speaker\": current_speaker, \n",
        "      \"start\": start_time, \n",
        "      \"stop\": stop_time, \n",
        "      \"duration\": stop_time-start_time,\n",
        "      \"transcribed_text\": \"\"\n",
        "      })\n",
        "  # clear memory of diarization\n",
        "  del diarization\n",
        "  return result\n",
        "\n",
        "def audio_segments_get(wave_file_path):\n",
        "    temp_start = time.time()\n",
        "    WAVE_FILE = {'audio': wave_file_path}\n",
        "    logger.info(\"Identifying speakers. This will take a few minutes\")\n",
        "    waveform, sample_rate = Audio()(WAVE_FILE)\n",
        "    # delete the wave file to save space as we no longer need it\n",
        "    del waveform\n",
        "    return pipeline(WAVE_FILE)\n",
        "    \n",
        "\n",
        "\n",
        "#################### TRANSCRIPTION WITH WHISPER\n",
        "################################################################################\n",
        "## Whisper Transcribe\n",
        "\n",
        "def mp3_transcribe(mp3_path: str):\n",
        "  # load audio and pad/trim it to fit 30 seconds\n",
        "  audio = whisper.load_audio(mp3_path)\n",
        "  audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "  # make log-Mel spectrogram and move to the same device as the model\n",
        "  mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "  # decode the audio\n",
        "  options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)\n",
        "  result = whisper.decode(model, mel, options)\n",
        "  del audio\n",
        "  return result.text\n",
        "\n",
        "def mp3_get_index_from_name(chunk_path):\n",
        "  regex= r\"chunk_(\\d+)\"\n",
        "  found = re.findall(regex, chunk_path.split(\"/\")[-1])\n",
        "  return int(found[0])\n",
        "\n",
        "def convert_to_hms(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    remaining_seconds = int(seconds % 60)\n",
        "    milliseconds = int(round(seconds * 1000) % 1000)\n",
        "    return f\"{hours}:{minutes:02d}:{remaining_seconds:02d}.{milliseconds:03d}\"\n",
        "\n",
        "def transcript_get(audio_segments, no_speaker=False):\n",
        "  transcript = \"\"\n",
        "  if no_speaker:\n",
        "      for segment in audio_segments:\n",
        "        transcript += f\"{segment['transcribed_text']} \\n\"\n",
        "  else:\n",
        "    for segment in audio_segments:\n",
        "      t_start = convert_to_hms(segment['start'])\n",
        "      t_stop = convert_to_hms(segment['stop'])\n",
        "      transcript += f\"\"\"{t_start}-{t_stop}: {segment['speaker']} - {segment['transcribed_text']} \\n\"\"\"\n",
        "  return transcript\n",
        "\n",
        "def mp3_chunks_transcribe(audio_segments):\n",
        "  chunks = glob.glob(path_split_mp3s + \"*.mp3\")\n",
        "\n",
        "  for index, chunk_path in enumerate(chunks):\n",
        "    segment_index = mp3_get_index_from_name(chunk_path)\n",
        "\n",
        "    speaker_seg = audio_segments[segment_index]\n",
        "\n",
        "    # by splitting on periods, the len of a regular chunk is 2 and anything\n",
        "    # higher will have a multiple sub parts\n",
        "    file_name_split = chunk_path.split(\"/\")[-1].split(\".\")\n",
        "    # if there are multiple sub parts to one section, we need to append the \n",
        "    # scripts together to complete one chunk. \n",
        "    if len(file_name_split) > 2:\n",
        "      speaker_seg['transcribed_text'] += mp3_transcribe(chunk_path) + \" \"\n",
        "    else:\n",
        "      speaker_seg['transcribed_text'] = mp3_transcribe(chunk_path)\n",
        "\n",
        "    # update the speaker segment\n",
        "    speaker_seg = audio_segments[segment_index]\n",
        "    if index % 25:\n",
        "      logger.info(f\"Transcribed {index} out of {len(chunks)}\")\n",
        "\n",
        "  return audio_segments\n",
        "\n",
        "\n",
        "#################### ML MODEL SUMMARIZATION\n",
        "################################################################################\n",
        "def summy_summarize(text, sentence_count=10):\n",
        "  result = \"\"\n",
        "  # Summarize using sumy LexRank\n",
        "  LANGUAGE = \"english\"\n",
        "  SENTENCES_COUNT= sentence_count\n",
        "  parser = PlaintextParser.from_string(text, Tokenizer(LANGUAGE))\n",
        "  stemmer = Stemmer(LANGUAGE)\n",
        "\n",
        "  summarizer = Summarizer(stemmer)\n",
        "  summarizer.stop_words = get_stop_words(LANGUAGE)\n",
        "\n",
        "  for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
        "    result += str(sentence) + \" \"\n",
        "  # free up mem\n",
        "  del parser\n",
        "  del stemmer\n",
        "  del summarizer\n",
        "  return result\n",
        "\n",
        "def break_up_text(tokens, chunk_size, overlap_size):\n",
        "  if len(tokens) <= chunk_size:\n",
        "    yield tokens\n",
        "  else:\n",
        "    chunk = tokens[:chunk_size]\n",
        "    yield chunk\n",
        "    yield from break_up_text(tokens[chunk_size-overlap_size:], chunk_size, overlap_size)\n",
        "\n",
        "def break_up_transcript_to_chunks(text, chunk_size=2000, overlap_size=100):\n",
        "  tokens = word_tokenize(text)\n",
        "  return list(break_up_text(tokens, chunk_size, overlap_size))\n",
        "\n",
        "def convert_to_detokenized_text(tokenized_text):\n",
        "  prompt_text = \" \".join(tokenized_text)\n",
        "  prompt_text = prompt_text.replace(\" 's\", \"'s\")\n",
        "  return prompt_text\n",
        "\n",
        "# handle the rate limiting of API calls\n",
        "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
        "def completions_with_backoff(**kwargs):\n",
        "  return openai.Completion.create(**kwargs)\n",
        "\n",
        "\n",
        "def openai_make_summarization(text):\n",
        "  # this was inspired by https://sungkim11.medium.com/how-to-get-around-openai-gpt-3-token-limits-b11583691b32\n",
        "  # split text up by max tokens\n",
        "  chunks = break_up_transcript_to_chunks(text)\n",
        "  de_tokenized_chunks = [{\"index\": i, \"summary\":\"\", \"chunk\": convert_to_detokenized_text(chunk)} for i, chunk in enumerate(chunks)]\n",
        "  logger.info(f\"Breaking up the transcript into {len(de_tokenized_chunks)} chunks for summarizing\")\n",
        "  summary = \"\"\n",
        "  \n",
        "  # check to see if the partial summary is present. If it is, load it\n",
        "  # the OpenAI API is not reliable service and sometimes is overloaded. This will\n",
        "  # capture the current \n",
        "  partial_summary = json_load(file_path_temp_summary)\n",
        "  # if there was not a partial temp summary\n",
        "  if partial_summary == False:\n",
        "    starting_index = 0\n",
        "    partial_summary = []\n",
        "  else:\n",
        "    logger.info(\"A partial summary was found. Picking up where we left off\")\n",
        "\n",
        "  for i, chunk in enumerate(de_tokenized_chunks):\n",
        "    # if there is not a summary, process it\n",
        "    if chunk['summary'] == \"\":\n",
        "      try:\n",
        "        logger.info(f\"Making Summarizing OpenAPI call\")\n",
        "        res = completions_with_backoff(\n",
        "            model=\"text-davinci-003\",\n",
        "            prompt=chunk['chunk'] + \"\\n\\ntl;dr\",\n",
        "            temperature= 0.7,\n",
        "            max_tokens= 1700,  \n",
        "            top_p= 1, \n",
        "            frequency_penalty= 0.0, \n",
        "            presence_penalty= 1\n",
        "          )\n",
        "        partial_summary.append({\"index\": i, \"summary\": res[\"choices\"][0][\"text\"].strip() + \"\\n\"})\n",
        "\n",
        "      except Exception as e:\n",
        "        logger.error(f\"While summarizing, ran into the following \\n {e}.\")\n",
        "        logger.info(\"No worries. Storing the progress made. Try again in a few hours.\")\n",
        "        logger.info(\"Check https://status.openai.com/ for more information\")\n",
        "        logger.info(\"This code will pick up where it left off to reduce cost \\\n",
        "          by not resummarizing what's already been done\")\n",
        "        json_save_to(partial_summary, file_path_temp_summary)\n",
        "        logger.info(\"Shutting runtime off\")\n",
        "        runtime.unassign()\n",
        "    # aggregate the summaries into one\n",
        "    summary += res[\"choices\"][0][\"text\"].strip() + \"\\n\"\n",
        "    \n",
        "  return summary\n",
        "  \n",
        "\n",
        "def summarize(transcript):\n",
        "  if summarization_tool.startswith(\"GPT3\"):\n",
        "    return openai_make_summarization(transcript)\n",
        "  else:\n",
        "    return summy_summarize(transcript, sentence_count=10)\n",
        "\n",
        "\n",
        "def transcript_wadsworth_constant(audio_segments):\n",
        "  # cut out the ads and outros for summary\n",
        "  no_speaker = transcript_get(audio_segments, no_speaker=True)\n",
        "  # how many sentences are there\n",
        "  count = len(no_speaker.split(\"\\n\"))\n",
        "  num_skip = math.ceil(count* (percent_sentences_to_skip/100))\n",
        "  temp_speaker = \"\"\n",
        "  for i in no_speaker.split(\"\\n\")[num_skip:-num_skip]:\n",
        "    temp_speaker += i + \"\\n\"\n",
        "  return temp_speaker\n",
        "\n",
        "\n",
        "################################################################################\n",
        "########################## MAIN ################################################\n",
        "################################################################################\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "## pull down the podcast\n",
        "logger.info(\"Grabbing the latest podcast xml feed\")\n",
        "feed_data = podcast_feed_download(podcast_xml)\n",
        "tokens = 0\n",
        "\n",
        "#################### PATH CREATION/VALIDATION\n",
        "################################################################################\n",
        "path_working_base_dir = os.path.join(path_to_use, feed_data['title'])\n",
        "path_full_mp3 = os.path.join(path_working_base_dir, \"full_mp3/\")\n",
        "path_full_wave = os.path.join(path_working_base_dir, \"full_wav/\")\n",
        "path_split_mp3s = os.path.join(path_full_mp3, \"split_mp3s/\")\n",
        "path_completed_transcripts = os.path.join(path_working_base_dir, \"transcripts/\")\n",
        "\n",
        "logger.info(\"Making sure that the needed directories that we need exist and/or creating as needed\")\n",
        "_ = file_path_validate_get(path_to_use, \"\")\n",
        "_ = file_path_validate_get(path_full_mp3, \"\")\n",
        "_ = file_path_validate_get(path_full_wave, \"\")\n",
        "_ = file_path_validate_get(path_split_mp3s, \"\")\n",
        "_ = file_path_validate_get(path_completed_transcripts, \"\")\n",
        "\n",
        "## save the podcast feed\n",
        "feed_json_path = path_working_base_dir + f\"/{feed_data['title']}_podcast_feed.json\"\n",
        "json_save_to(feed_data, feed_json_path)\n",
        "logger.info(f\"Saving podcast episodes for tracking at {feed_json_path}\")\n",
        "\n",
        "\n",
        "index = 0\n",
        "entry_duration = []\n",
        "\n",
        "if num_of_episodes==0:\n",
        "  logger.info(\"You have selected all episodes in the podcast. Know that this will probably take multiple sessions to complete.\")\n",
        "  num_of_episodes = len(feed_data['entries'])\n",
        "else:\n",
        "  logger.info(f\"You have selected to download {num_of_episodes} episodes\")\n",
        "# allow for downloading on specific number of files\n",
        "for entry in feed_data['entries'][:num_of_episodes]:\n",
        "  entry_start=time.time()\n",
        "\n",
        "  logger.info(f\"Starting on {entry['title']}\")\n",
        "  mp3_file_path = path_full_mp3 + entry['file_name']\n",
        "  file_name_no_extension = entry['file_name'][:-4]\n",
        "  file_path_wave = path_full_wave + file_name_no_extension + \".wav\"\n",
        "  file_path_audio_segments = path_full_mp3 + file_name_no_extension + \"_audio_segments.json\"\n",
        "  file_path_transcript_path = path_completed_transcripts + f\"{file_name_no_extension}-speaker_transcript.txt\"\n",
        "  file_path_summary = path_completed_transcripts + f\"{file_name_no_extension}-summary.txt\"\n",
        "  file_path_temp_summary = path_full_mp3 + f\"{file_name_no_extension}-temp_summary.txt\"\n",
        "  \n",
        "  ## DOWNLOAD MP3\n",
        "  # check to see if the mp3 already exists\n",
        "  if os.path.isfile(mp3_file_path) == False:\n",
        "    logger.info(f\"Downloading {entry['title']}\")\n",
        "    mp3_download(url=entry['href'], file_name=entry['file_name'], save_path=path_full_mp3)\n",
        "    \n",
        "\n",
        "  ### DIARIZATION\n",
        "  if identify_speakers == True:\n",
        "    # delete the split mp3s\n",
        "    logger.info(\"Clearing the working cache\")\n",
        "    files_in_folder_delete(path_split_mp3s)\n",
        "    \n",
        "    start_diarization = time.time()\n",
        "\n",
        "    #check to see if the segment file already exists\n",
        "    if os.path.isfile(file_path_audio_segments) == False:\n",
        "      # convert to wave file as diarization requires wav\n",
        "      logger.info(\"Converting the mp3 to wav for speaker identification\")\n",
        "      mp3_convert_to_wav(mp3_file_path=mp3_file_path, wav_file_path=file_path_wave)\n",
        "      # get the diarization and then get the output in the format we need it in\n",
        "      audio_segments = capture_speaker_changes(audio_segments_get(file_path_wave))\n",
        "      # save the speaker segments\n",
        "      logger.info(\"Saving the speaker segments\")\n",
        "      json_save_to(audio_segments, file_path_audio_segments)\n",
        "      logger.info(\"Deleting the wav file\")\n",
        "      files_in_folder_delete(path_full_wave)\n",
        "      logger.info(f\"Speaker Identification has completed in {time.time()-start_diarization} seconds\")\n",
        "    # load the speaker segments if \n",
        "    else:\n",
        "      logger.info(\"Found existing speaker segmentation file. Loading...\")\n",
        "      audio_segments = json_load(file_path_audio_segments)\n",
        "\n",
        "    ##### MP3 SPLIT UP & WHISPER Transcribe\n",
        "\n",
        "    if os.path.isfile(file_path_transcript_path) == False:\n",
        "      start_whisper = time.time()\n",
        "      #splitting up the mp3 to smaller chunks to make it easier for whisper &\n",
        "      #requires less ram and prefers 30 second chunks or less\n",
        "      logger.info(\"Splitting the MP3 based on speakers\")\n",
        "      start_split = time.time()\n",
        "      mp3_split_speaker_segments(audio_segments, mp3_file_path)\n",
        "      logger.info(f\"Splitting MP3 into chunks has completed in {time.time()-start_split} seconds\")\n",
        "      audio_segments = mp3_chunks_transcribe(audio_segments)\n",
        "      logger.info(f\"Transcription has completed in {time.time()-start_whisper} seconds\")\n",
        "      # save the audio_segments\n",
        "      json_save_to(audio_segments, file_path_audio_segments)\n",
        "      # save the transcript for this episode\n",
        "      file_write(file_path_transcript_path, transcript_get(audio_segments))\n",
        "      \n",
        "      \n",
        "    ### SUMMARIZE\n",
        "    if os.path.isfile(file_path_summary) == False and summarize_episode == True:\n",
        "      summary = summarize(transcript_wadsworth_constant(audio_segments))\n",
        "      file_write(file_path_summary, summary)\n",
        "      \n",
        "  \n",
        "  # user just wants a summary\n",
        "  else:\n",
        "    # transcribe the file if the file doesn't already exist\n",
        "    if os.path.isfile(file_path_transcript_path) == False:\n",
        "      logger.info(\"Starting transcription. 1hr episode takes around 20-35 min.\")\n",
        "      start_whisper = time.time()\n",
        "      return_code = subprocess.call(f\"whisper {mp3_file_path} --language en --model {whisper_model} --output_format json --model_dir {path_ml_models} --output_dir {path_split_mp3s} --verbose True\", shell=True)\n",
        "      logger.info(f\"Transcription has completed in {time.time()-start_whisper} seconds\")\n",
        "\n",
        "      logger.info(f\"Converting the output to template\")\n",
        "      # calling CLI whisper, it generates a json file that we will convert\n",
        "      # to the template\n",
        "      temp_json = glob.glob(path_split_mp3s + \"*.json\")[0]\n",
        "      data = json_load(temp_json)\n",
        "      transcript = data['text']\n",
        "      audio_segments = []\n",
        "      for row in data['segments']:\n",
        "        audio_segments.append({ \n",
        "            \"speaker\": \"SPEAKER\",\n",
        "            \"start\": row['start'], \n",
        "            \"stop\": row['end'], \n",
        "            \"duration\": row['end']-row['start'],\n",
        "            \"transcribed_text\": row[\"text\"]\n",
        "          })\n",
        "      json_save_to(audio_segments, file_path_audio_segments)\n",
        "      os.remove(temp_json)\n",
        "      json_save_to(transcript_get(audio_segments), file_path_transcript_path)\n",
        "      # converting audio_segments to the transcript\n",
        "      file_write(file_path_transcript_path, transcript_get(audio_segments))\n",
        "      logger.info(f\"You can find this file at {file_path_transcript_path}\")\n",
        "    \n",
        "    if os.path.isfile(file_path_summary) == False and summarize_episode == True:\n",
        "      summary = summarize(transcript_wadsworth_constant(audio_segments))\n",
        "      logger.info(f\"Saving the summary at {file_path_summary}\")\n",
        "      file_write(file_path_summary, summary)\n",
        "      with open(file_path_summary, 'w') as f:\n",
        "            f.write(summary)\n",
        "\n",
        "\n",
        "  dur = convert_to_hms(time.time() - entry_start)\n",
        "  entry_duration.append(dur)\n",
        "  logger.info(f\"This episode took {dur}\")\n",
        "\n",
        "  # update the podcast entries\n",
        "  feed_data['entries'][index] = entry\n",
        "  # update the file\n",
        "  json_save_to(feed_data, feed_json_path)\n",
        "  index += 1\n",
        "\n",
        "logger.info(f\"Completed the summarization of {num_of_episodes} episodes of the podcast\")\n",
        "display(str(time.time()-start))\n",
        "if delete_mp3s_when_done:\n",
        "  logger.info(\"Deleting podcast mp3s to conserve space\")\n",
        "  files_in_folder_delete(path_full_mp3, file_type: 'mp3')\n",
        "# kill this session\n",
        "if auto_shutoff:\n",
        "  logger.info(\"Shutting runtime off\")\n",
        "  runtime.unassign()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A0BvYKeDUINm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (v3.9.13:6de2ca5339, May 17 2022, 11:37:23) \n[Clang 13.0.0 (clang-1300.0.29.30)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}